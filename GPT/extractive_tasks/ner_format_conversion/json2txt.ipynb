{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab7e6c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe prediction files are stored in a nested folder structure based on the dataset, \\nGPT model version, and the shot setting. The expected directory structure is:\\n\\ndata/\\n├── NCBI_Disease/\\n│   ├── GPT3.5/\\n│   │   └── NCBI_Disease_gpt3.5_5s.json\\n│   └── GPT4/\\n│       └── NCBI_Disease_gpt4_5s.json\\n└── BC5CDR_Chemical/\\n    ├── GPT3.5/\\n    │   └── BC5CDR_Chemical_gpt3.5_5s.json\\n    └── GPT4/\\n        └── BC5CDR_Chemical_gpt4_5s.json\\n        \\nThe expected output is\\noutput/\\n├── NCBI_Disease_gpt3.5_5s_gold_span.txt\\n├── NCBI_Disease_gpt3.5_5s_pre_span.txt\\n└── ...\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The prediction files are stored in a nested folder structure based on the dataset, \n",
    "GPT model version, and the shot setting. The example input structure is:\n",
    "\n",
    "data/\n",
    "├── NCBI_Disease/\n",
    "│   ├── GPT3.5/\n",
    "│   │   └── NCBI_Disease_gpt3.5_5s.json\n",
    "│   └── GPT4/\n",
    "│       └── NCBI_Disease_gpt4_5s.json\n",
    "└── BC5CDR_Chemical/\n",
    "    ├── GPT3.5/\n",
    "    │   └── BC5CDR_Chemical_gpt3.5_5s.json\n",
    "    └── GPT4/\n",
    "        └── BC5CDR_Chemical_gpt4_5s.json\n",
    "        \n",
    "The example output structure is\n",
    "output/\n",
    "├── NCBI_Disease_gpt3.5_5s_gold_span.txt\n",
    "├── NCBI_Disease_gpt3.5_5s_pre_span.txt\n",
    "└── ...\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ee8719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25dd3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the base directories exist\n",
    "base_converted_dir = './converted_bio_output'\n",
    "base_output_dir = './output'\n",
    "if not os.path.exists(base_converted_dir):\n",
    "    os.makedirs(base_converted_dir)\n",
    "if not os.path.exists(base_output_dir):\n",
    "    os.makedirs(base_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb5eeef6-ac54-4346-aa38-f6443fe717ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(label_file, eval_score_file='', sep_tag_type='tab', eval_type='ner', exact=False, labels=None):    \n",
    "    sep_tag = ' ' if sep_tag_type=='space' else '\\t'    \n",
    "    try:\n",
    "        if type(label_file) is str:\n",
    "            gold, predict = load_combined_bio( label_file, sep_tag)\n",
    "        elif len(label_file) == 2:\n",
    "            gold_label_file = label_file[0]\n",
    "            pred_label_file = label_file[1]\n",
    "            gold = load_bio(gold_label_file, sep_tag)\n",
    "            predict = load_bio(pred_label_file, sep_tag)\n",
    "        else:\n",
    "            return\n",
    "    except Exception as e:\n",
    "        return\n",
    "    gold_spans = load_spans( gold, eval_type )\n",
    "    predict_spans = load_spans( predict, eval_type )\n",
    "\n",
    "    if not labels:\n",
    "        labels = list({item[2:] for item in set(gold).union(set(predict)) if item[2:] and item != 'O'})\n",
    "        labels = [item for item in labels if item != 'O']\n",
    "        labels.sort()\n",
    "    else:\n",
    "        labels = [item.strip() for item in labels.split(',') if item.strip()]\n",
    "    eval_results = []\n",
    "    if exact:\n",
    "        score_cols = 'P\\tR\\tF1\\tright\\tpredict\\tgold\\tSemantic'\n",
    "        eval_results.append(score_cols)\n",
    "    else:\n",
    "        score_cols = 'P(exact)\\tR(exact)\\tF1(exact)\\tP(relax)\\tR(relax)\\tF1(relax)\\tright\\tright_predict\\tright_gold\\tpredict\\tgold\\tSemantic'\n",
    "        eval_results.append(score_cols)\n",
    "    gold_span = []\n",
    "    predict_span = []\n",
    "    for k in sorted(gold_spans.keys(),key=lambda x:labels.index(x)):\n",
    "        gold_span = gold_spans[k]\n",
    "\n",
    "        if k in predict_spans:\n",
    "            predict_span = predict_spans[k]\n",
    "        else:\n",
    "            predict_span = []\n",
    "    return gold_span, predict_span\n",
    "\n",
    "def load_bio( result_file, sep_tag='\\t' ):\n",
    "    result = []\n",
    "    with open( result_file ) as infile:\n",
    "        for line in infile:\n",
    "            if line.strip() == '':\n",
    "                result.append( 'O' )\n",
    "                continue\n",
    "            # ignore disjoint entities for now\n",
    "            #line = line.replace( 'B-DDisease_Disorder', 'B-Disease_Disorder' )\n",
    "            #line = line.replace( 'B-HDisease_Disorder', 'B-Disease_Disorder' )\n",
    "            #line = line.replace( 'I-DDisease_Disorder', 'I-Disease_Disorder' )\n",
    "            #line = line.replace( 'I-HDisease_Disorder', 'I-Disease_Disorder' )\n",
    "            result.append( line.split(sep_tag)[-1].strip('\\n') )\n",
    "\n",
    "    return result\n",
    "\n",
    "# load spans: support eval_type as 'ner' or 'classification'\n",
    "def load_spans( labels, eval_type='ner' ):\n",
    "    spans = {}\n",
    "    for i in range( len( labels ) ):\n",
    "        if eval_type == 'classification':\n",
    "            label = labels[i]\n",
    "            spans.setdefault( label, [] )\n",
    "            spans[label].append((i, i+1))\n",
    "            continue\n",
    "        else:\n",
    "            label = labels[i]\n",
    "            if type(label) == list:\n",
    "                print('Warning: label is list {}'.format(label))\n",
    "            if label.startswith( 'B-' ):\n",
    "                s = i\n",
    "                e = i + 1\n",
    "                sem = label[ 2: ]\n",
    "                # found an entity\n",
    "                for j in range( i + 1, len( labels ) ):\n",
    "                    e = j\n",
    "                    if labels[j] != 'I-' + sem:\n",
    "                        break\n",
    "                spans.setdefault( sem, [] )\n",
    "                spans[ sem ].append( ( s, e ) )\n",
    "            if label.startswith( 'DB-' ):\n",
    "                s = i\n",
    "                e = i + 1\n",
    "                sem = label[ 3: ]\n",
    "                # found an entity\n",
    "                for j in range( i + 1, len( labels ) ):\n",
    "                    e = j\n",
    "                    if labels[j] != 'DI-' + sem:\n",
    "                        break\n",
    "                spans.setdefault( sem, [] )\n",
    "                spans[ sem ].append( ( s, e ) )\n",
    "\n",
    "            if label.startswith( 'HB-' ):\n",
    "                s = i\n",
    "                e = i + 1\n",
    "                sem = label[ 3: ]\n",
    "                # found an entity\n",
    "                for j in range( i + 1, len( labels ) ):\n",
    "                    e = j\n",
    "                    if labels[j] != 'HI-' + sem:\n",
    "                        break\n",
    "                spans.setdefault( sem, [] )\n",
    "                spans[ sem ].append( ( s, e ) )\n",
    "\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b9556b-296a-4c34-9102-d641e0094a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['NCBI_Disease','BC5CDR_Chemical']:\n",
    "    for shot in ['5s']:\n",
    "        for gpt in ['3.5','4']:\n",
    "            prediction_dict = json.load(open(f'./data/{dataset}/GPT{gpt}/{dataset}_gpt{gpt}_{shot}.json'))\n",
    "            !mkdir ./converted_bio_output/{dataset}_gpt{gpt}_{shot}/\n",
    "            \n",
    "            gold_spans=[]\n",
    "            pre_spans = []\n",
    "\n",
    "            for index,instance in enumerate(prediction_dict):\n",
    "                f1 = f'./converted_bio_output/{dataset}_gpt{gpt}_{shot}/{index}_pre.bio'\n",
    "                f2 = f'./converted_bio_output/{dataset}_gpt{gpt}_{shot}/{index}_gold.bio'\n",
    "                f_pre = open(f1,'w')\n",
    "                f_gold = open(f2,'w')\n",
    "                tokens = instance['sentence']\n",
    "                golds = instance['gold']\n",
    "                preds = instance['pred']\n",
    "            \n",
    "                gold_bio = []\n",
    "                for token,gold in zip(tokens,golds):\n",
    "                    if dataset == 'NCBI_Disease':\n",
    "                        if gold == 'B':gold='B-disease'\n",
    "                        if gold == 'I':gold='I-disease'\n",
    "                    if dataset == 'BC5CDR_Chemical':\n",
    "                        if gold == 'B':gold='B-chemical'\n",
    "                        if gold == 'I':gold='I-chemical'\n",
    "                    gold_bio.append(token+'\\t'+gold+'\\n')\n",
    "                pred_bio = []\n",
    "                for token,pre in zip(tokens,preds):\n",
    "                    if dataset == 'NCBI_Disease':\n",
    "                        \n",
    "                        if pre == 'B':pre='B-disease'\n",
    "                        if pre == 'I':pre='I-disease'\n",
    "                    if dataset == 'BC5CDR_Chemical':\n",
    "                        if pre == 'B':pre='B-chemical'\n",
    "                        if pre == 'I':pre='I-chemical'\n",
    "                    pred_bio.append(token+'\\t'+pre+'\\n')\n",
    "                    \n",
    "                f_pre.writelines(pred_bio)\n",
    "                f_pre.write('\\n')\n",
    "                f_gold.writelines(gold_bio)\n",
    "                f_gold.write('\\n')    \n",
    "                    \n",
    "                f_pre.close()\n",
    "                f_gold.close()\n",
    "                    \n",
    "            \n",
    "                label_file = (f2,f1)\n",
    "                gold_span,pre_span = evaluate(label_file)\n",
    "                gold_spans.append(gold_span)\n",
    "                pre_spans.append(pre_span)\n",
    "            with open(f'./output/{dataset}_gpt{gpt}_{shot}_gold_span.txt','w') as gold_span_output:\n",
    "                gold_span_output.write(str(gold_spans))\n",
    "            with open(f'./output/{dataset}_gpt{gpt}_{shot}_pre_span.txt','w') as gold_span_output:\n",
    "                gold_span_output.write(str(pre_spans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ebceda-0e03-4b21-80ad-7e746a7f3439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
